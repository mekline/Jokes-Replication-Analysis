names(myster) = c('Group','Task', 'ROIName', 'ROI','contrastName', 'sterr')
mystats = merge(mystats,myster)
mystats$se_up = mystats$themean + mystats$sterr
mystats$se_down = mystats$themean - mystats$sterr
#Edit! We should be doing bootstrapped 95% confidence intervals instead! calculate them from allSigChange
#then merge into mystats
bootup <- function(mylist){
foo <- bootstrap(mylist, 1000, mean)
return(quantile(foo$thetastar, 0.975)[1])
}
bootdown <- function(mylist){
foo <- bootstrap(mylist, 1000, mean)
return(quantile(foo$thetastar, 0.025)[1])
}
mybootup = aggregate(toGraph$sigChange, by=list(toGraph$Group, toGraph$task, toGraph$ROIName, toGraph$ROI, toGraph$contrastName), bootup)
names(mybootup) = c('Group', 'Task', 'ROIName', 'ROI','contrastName', 'bootup')
mybootdown = aggregate(toGraph$sigChange, by=list(toGraph$Group, toGraph$task, toGraph$ROIName, toGraph$ROI, toGraph$contrastName), bootdown)
names(mybootdown) = c('Group', 'Task', 'ROIName', 'ROI','contrastName', 'bootdown')
mystats = merge(mystats,mybootup)
mystats = merge(mystats,mybootdown)
#########
# Effect size reports
#########
#For the main analysis in the paper (signal change jokes>nonjokes) we'll report  a simple measure of effect size: the
#mean signal change in each system. Here they are:
eff <- mystats %>%
filter(ROIName == 'LocalizerAverage') %>%
filter(contrastName == 'joke' | contrastName == 'lit') %>%
dplyr::select(Group, contrastName,themean) %>%
spread(contrastName, themean) %>%
mutate(sigChange = joke-lit)
#########
# Graphs!
#########
#Now we can use the information stored in mystats to make pretty graphs! This could be done in excel too by printing mystats
#Change to figs output folder
setwd("./figs")
#Select the rows we want for each graph, and order them how we want! For now, localizerAverage will just come first in all sets
mystats$contNo <- 1
mystats[mystats$contrastName == 'joke',]$contNo <- 1
mystats[mystats$contrastName == 'lit',]$contNo <- 2
mystats[mystats$contrastName == 'high',]$contNo <- 1
mystats[mystats$contrastName == 'med',]$contNo <- 2
mystats[mystats$contrastName == 'low',]$contNo <- 3
#mystats = arrange(mystats, ROI)
mystats = arrange(mystats, contNo)
#Add a new col grouping to separate out the localizer average
mystats$ROIGroup <- ""
mystats[mystats$ROIName == "LocalizerAverage",]$ROIGroup <- "across fROIs"
mystats = arrange(mystats, desc(ROIGroup))
#Changes for prettiness
mystats[mystats$ROIName=="LocalizerAverage",]$ROIName <- "average across fROIs"
mystats$ROIName <- str_wrap(mystats$ROIName, width = 4)
mystats$contrastLabel <- mystats$contrastName
mystats[mystats$contrastName == "joke",]$contrastLabel <- "Jokes\n  "
mystats[mystats$contrastName == "lit",]$contrastLabel <- "Non-jokes\n   "
mystats[mystats$contrastName == "high",]$contrastLabel <- "high\n  "
mystats[mystats$contrastName == "med",]$contrastLabel <- "med\n   "
mystats[mystats$contrastName == "low",]$contrastLabel <- "low\n  "
#Subsets & Ordering (elaborate code, probably can condense these; ggplot is finicky at orders)
RHLang = filter(mystats, Group == 'RHLang')
RHLang <- RHLang[order(RHLang$ROI),]
RHLang$PresOrder = c(13,14, 9,10, 7,8, 11,12, 3,4,5,6,1,2) #Reorder for standard presentation!
RHLang <- RHLang[order(RHLang$PresOrder),]
RHLang = arrange(RHLang, desc(ROIGroup))
LHLang = filter(mystats, Group == 'LHLang')
LHLang <- LHLang[order(LHLang$ROI),]
LHLang$PresOrder = c(13,14, 9,10, 7,8, 11,12, 3,4,5,6,1,2)
LHLang <- LHLang[order(LHLang$PresOrder),]
LHLang = arrange(LHLang, desc(ROIGroup))
MDLeft = filter(mystats, Group == 'MDLeft')
MDLeft <- MDLeft[order(MDLeft$ROI),]
MDLeft = arrange(MDLeft, desc(ROIGroup))
MDRight = filter(mystats, Group == 'MDRight')
MDRight <- MDRight[order(MDRight$ROI),]
MDRight = arrange(MDRight, desc(ROIGroup))
ToM = filter(mystats, Group == 'ToM', Task == 'Jokes')
ToM <- ToM[order(ToM$ROI),]
# ToM$PresOrder = c(1,2,3,4,9,10,5,6,7,8,11,12,13,14) This is for when VMPFC is NOT included
ToM$PresOrder = c(1,2,3,4,9,10,5,6,7,8,11,12,13,14,15,16) #This is for all contrasts
ToM <- ToM[order(ToM$PresOrder),]
ToM = arrange(ToM, desc(ROIGroup))
ToMCustom = filter(mystats, Group == 'ToM', Task == 'JokesCustom')
ToMCustom <- arrange(ToMCustom, contNo)
ToMCustom <- ToMCustom[order(ToMCustom$ROI),]
ToMCustom$PresOrder = c(1,2,3,4,5,6,13,14,15,7,8,9,10,11,12,16,17,18,19,20,21, 22, 23, 24)
ToMCustom <- ToMCustom[order(ToMCustom$PresOrder),]
ToMCustom = arrange(ToMCustom, desc(ROIGroup))
#Graphing function!
makeBar = function(plotData,ylow=-0.5,yhigh=2.5, mycolors = c("gray35", "gray60")) {
#freeze factor orders
plotData$ROIName <- factor(plotData$ROIName, levels = unique(plotData$ROIName))
plotData$ROIGroup <- factor(plotData$ROIGroup, levels = unique(plotData$ROIGroup))
plotData$contrastLabel <- factor(plotData$contrastLabel, levels = unique(plotData$contrastLabel))
myfi = paste(plotData$Group[1], '_', plotData$Task[2], '.jpg', sep="")#filename
print(myfi)
ggplot(data=plotData, aes(x=ROIName, y=themean, fill=contrastLabel)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=bootdown, ymax=bootup), colour="black", width=.1, position=position_dodge(.9)) +
coord_cartesian(ylim=c(ylow,yhigh)) +
scale_y_continuous(breaks = seq(-0.5, 2.5, 0.5))+
xlab('') +
ylab(str_wrap('% signal change over fixation', width=18)) +
scale_fill_manual(name="", values=mycolors) +
theme_bw() +
theme(legend.key = element_blank()) +
theme(text = element_text(size = 40)) +
facet_grid(~ROIGroup, scale='free_x', space='free_x') +
theme(strip.background = element_blank()) +
theme(strip.text = element_blank())
# Optional, remove for RHLang and ToMCustom since we want the legend there...
#+ theme(legend.position="none")
ggsave(filename=myfi, width=length(unique(plotData$ROIName))*2.2, height=6.1)
}
makeBar(LHLang)
makeBar(RHLang)
makeBar(MDLeft)
makeBar(MDRight)
makeBar(ToM, -0.5, 1)
makeBar(ToMCustom, -0.5, 1, c("high\n  "= "gray35", "med\n   "= "gray50", "low\n  "= "gray65"))
library(tidyr)
library(dplyr)
library(pwr)
#Set wd!
setwd("/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/analysis_pipeline")
#Make sure allSigChange is loaded. If it's not, run 2figs_resp_jokes.R to at least line 108
View(allSigChange)
#For the replication, commenting this out, we'll find out in a minute if any localizer-to-localizer
#measurements are not robust enough
#New 10/12: Localizer analysis shows that VMPFC localizer doesn't come out in this dataset, so remove it from
#the joke-lit tests for ToM and ToM custom (but leave it for the localizer itself)
#Replication: Nothing looks like it should be left out yet!
#allSigChange = allSigChange %>%
#  filter(!(Group == 'ToM' & ROIName =='VMPFC')) %>%
#  filter(!(Group == 'ToMCustom' & ROIName =='VMPFC'))
#######
# Calculate T Tests
#######
allTests <- allSigChange %>%
group_by(Group, task)%>%
summarize(familySize = length(unique(ROI))) %>%
merge(allSigChange) %>%
group_by(Group, task, ROI, ROIName, contrastName, familySize) %>%
summarise(t = t.test(sigChange, mu=0,alt='greater')$statistic,
p = t.test(sigChange, mu=0,alt='greater')$p.value) %>%
ungroup()%>%
group_by(Group, contrastName)%>%
mutate(p.adj = p.adjust(p, method="fdr", n=familySize[1]))%>%
ungroup()
View(allTests)
zz = file('localizer_t_tests_all.csv', 'w')
write.csv(allTests, zz, row.names=FALSE)
close(zz)
#Do corrections ever matter?
allTests <- allTests %>%
mutate(sig = p < 0.05) %>%
mutate(sigCor = p.adj < 0.05) %>%
mutate(mismatch = sig != sigCor)
View(filter(allTests,mismatch))
t task is Sentences - Nonwords.
#Convention: when all tests go one way, report them together as follows:
reportTests <- function(ts, ps){
if (all(ps > 0.05)){
paste('all insig, ts <', max(ts), 'ps>', min(ps))
} else if (all(ps < 0.05)){
paste('all sig, ts >', min(ts), 'ps<', max(ps))
} else {
'explore...'
}
}
###
#RESP LOCALIZER
allTests %>%
filter(Group == 'LHLang', task == 'Lang', contrastName == 'S-N') %>%
summarise(n(), sum(sig), reportTests(t,p)) #Convention: when all significant, report the largest p
allTests %>%
filter(Group == 'RHLang', task == 'Lang', contrastName == 'S-N') %>%
summarise(n(), sum(sig), reportTests(t,p)) #Orig found a surprise nonsig, but not in the replication
allTests %>%
filter(Group == 'MDLeft', task == 'MD', contrastName == 'H-E') %>%
summarise(n(), sum(sig), reportTests(t,p)) #Orig found a surprise nonsig, but not in the replication
allTests %>%
filter(Group == 'MDRight', task == 'MD', contrastName == 'H-E') %>%
summarise(n(), sum(sig), reportTests(t,p)) #Orig found a surprise nonsig, but not in the replication
allTests %>%
filter(Group == 'ToM', task == 'ToM', contrastName == 'bel-pho') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'RHLang', contrastName == 'joke') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'RHLang', task == 'Jokes', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'RHLang', task == 'Jokes', contrastName == 'joke') %>%
summarise(n(), sum(sig), reportTests(t,p))
ilter(allTests, Group == 'RHLang', contrastName == 'joke', !sig)
filter(allTests, Group == 'RHLang', contrastName == 'joke', !sig)
allTests %>%
filter(Group == 'RHLang', task == 'Jokes', contrastName == 'lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'RHLang', contrastName == 'lit', !sig)
allTests %>%
filter(Group == 'RHLang', task == 'Jokes', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'LHLang', task == 'Jokes', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'MDRight', task == 'Jokes', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'MDRight', task == 'Jokes', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'MDRight', contrastName == 'joke-lit', !sig)
allTests %>%
filter(Group == 'MDLeft', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'ToM', task =='Jokes', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
library(tidyr)
library(dplyr)
library(lme4)
#Set wd!
setwd("/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/analysis_pipeline")
RHLangtoLang <- filter(allSigChange, Group == "RHLang", task == "Lang", contrastName == 'S' | contrastName == 'N')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = RHLangtoLang)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = RHLangtoLang)
anova(m1,m0)
LHLangtoLang <- filter(allSigChange, Group == "LHLang", task == "Lang", contrastName == 'S' | contrastName == 'N')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = LHLangtoLang)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = LHLangtoLang)
anova(m1,m0)
##MD to the MD task
MDRtoMD <- filter(allSigChange, Group == "MDRight", task == "MD", contrastName == 'H' | contrastName == 'E')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = MDRtoMD)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = MDRtoMD)
anova(m1,m0)
MDLtoMD <- filter(allSigChange, Group == "MDLeft", task == "MD", contrastName == 'H' | contrastName == 'E')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = MDLtoMD)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = MDLtoMD)
anova(m1,m0)
ToMtoToM <- filter(allSigChange, Group == "ToM", task =='ToM', contrastName == 'bel' | contrastName == 'pho')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = ToMtoToM)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = ToMtoToM)
anova(m1,m0)
RHLang <- filter(allSigChange, Group == "RHLang", task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = RHLang)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = RHLang)
anova(m1,m0)
LHLang <- filter(allSigChange, Group == "LHLang", task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = LHLang)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = LHLang)
anova(m1,m0)
MDRight <- filter(allSigChange, Group == "MDRight", task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = MDRight)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = MDRight)
anova(m1,m0)
MDLeft <- filter(allSigChange, Group == "MDLeft", task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = MDLeft)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = MDLeft)
anova(m1,m0)
ToM <- filter(allSigChange, Group == "ToM", task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = ToM)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = ToM)
anova(m1,m0)
MDRight <- filter(allSigChange, Group == "MDRight", task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = MDRight)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = MDRight)
anova(m1,m0)
#hypothesis: large between-system differences eat most of the variance.  Use joke-lit contrast value instead
ToM_MDRight_cont <- filter(allSigChange, Group == "ToM" | Group == "MDRight", task == 'Jokes', contrastName == 'joke-lit')
m1 <- lmer(sigChange ~ Group + (1|ROIName) + (Group|SubjectNumber), data = ToM_MDRight_cont)
m0 <- lmer(sigChange ~ 1 + (1|ROIName) + (Group|SubjectNumber), data = ToM_MDRight_cont)
anova(m1,m0)
ToM_RHLang_cont <- filter(allSigChange, Group == "ToM" | Group == "RHLang", task =='Jokes', contrastName == 'joke-lit')
m1 <- lmer(sigChange ~ Group + (1|ROIName) + (Group|SubjectNumber), data = ToM_RHLang_cont)
m0 <- lmer(sigChange ~ 1 + (1|ROIName) + (Group|SubjectNumber), data = ToM_RHLang_cont)
anova(m1,m0)
ToM_MDLeft_cont <- filter(allSigChange, Group == "ToM" | Group == "MDLeft", task == 'Jokes', contrastName == 'joke-lit')
m1 <- lmer(sigChange ~ Group + (1|ROIName) + (Group|SubjectNumber), data = ToM_MDLeft_cont)
m0 <- lmer(sigChange ~ 1 + (1|ROIName) + (Group|SubjectNumber), data = ToM_MDLeft_cont)
anova(m1,m0)
ToM_LHLang_cont <- filter(allSigChange, Group == "ToM" | Group == "LHLang", task == 'Jokes', contrastName == 'joke-lit')
m1 <- lmer(sigChange ~ Group + (1|ROIName) + (Group|SubjectNumber), data = ToM_LHLang_cont)
m0 <- lmer(sigChange ~ 1 + (1|ROIName) + (Group|SubjectNumber), data = ToM_LHLang_cont)
anova(m1,m0)
library(tidyr)
library(dplyr)
library(lme4)
library(ggplot2)
#(set your own wd first)
setwd("/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/analysis_pipeline")
behavdir = "/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/behavioral_data/Jokes"
#New  - read in the nicely formatted behavioral data we made!
behavdata = read.csv(paste(behavdir, '/all_behavioral_output.csv', sep=''))
#Make sure you have AllSigChange!
View(allSigChange)
#We need to make sure to match up the right participants, so here we add the list order that participants
#were loaded into the ToM initial first-level analyses.
participants = c('168_FED_20161228b_3T2',
'290_FED_20170426a_3T2',
'301_FED_20161217b_3T2',
'366_FED_20161205a_3T2',
'426_FED_20161215c_3T2',
'430_FED_20170426d_3T2',
'498_FED_20170210c_3T2',
'555_FED_20170426c_3T2',
'576_FED_20170414b_3T2',
'577_FED_20170414c_3T2',
'578_FED_20170414d_3T2',
'288_FED_20170412b_3T2',
'334_FED_20161221a_3T2',
'343_FED_20161208a_3T2',
'521_FED_20161228a_3T2',
'551_FED_20170412a_3T2',
'571_FED_20170412c_3T2',
'473_FED_20170210b_3T2',
'520_FED_20161227a_3T2',
'596_FED_20170426b_3T2')
participants = as.data.frame(participants)
participants$SubjectNumber = 1:nrow(participants)
participants$ID = participants$participant
allSigChange <- merge(allSigChange, participants, by=c('SubjectNumber'), all_x=TRUE, all_y=TRUE)
#(This drops subjects who didn't get included for the Jokes analyses!)
####
# Ratings
####
#Get average ratings per category per participant
behavdata$response <- as.numeric(as.character(behavdata$response))
jokeResponseChange <- behavdata %>%
filter(!is.na(response)) %>%
group_by(ID, category) %>%
summarise(meanResponse = mean(response)) %>%
spread(category, meanResponse) %>%
mutate(meanResponseChange = joke-nonjoke)
####
# Signal change
####
jokeSigChange <- allSigChange %>%
filter(contrastName == 'joke-lit', Group == 'ToM', task == 'Jokes', ROIName == 'LocalizerAverage')
#Merge the datasets!
bb <- merge(jokeResponseChange, jokeSigChange, by=c('ID'))
## REPORT STATS
cor(bb$meanResponseChange, bb$sigChange)
## Added an LM (no random slopes/intercepts! just 1 value/person)
m1 <- lm(sigChange ~ meanResponseChange, data = bb)
m0 <- lm(sigChange ~ 1, data = bb)
anova(m1,m0)
## MAKE PRETTY GRAPH
setwd("./figs")
coef(lm(meanResponseChange ~ sigChange, data = bb))
ggplot(data=bb, aes(y=sigChange, x=meanResponseChange)) +
geom_point() +
geom_smooth(method="lm", se=FALSE) +
scale_y_continuous(limits = c(-0.25, 0.50), breaks = seq(-0.25, 0.50, 0.25)) +
scale_x_continuous(limits = c(0, 1.75), breaks = seq(0, 2, 0.5)) +
xlab('average rating response \n(Jokes - Non-jokes)') +
ylab('avg. % signal change \n(Jokes - Non-jokes)') +
theme_bw() +
ggsave(filename="behav_activation.jpg", width=3, height=3)
#This file reads in ALL the %-signal-change values, per-participant, per-parcel, per-contrast,
# Those %-signal-change calculations are produced by the awesome toolbox analyses, and represent a single overall calculation
#derived for the whole parcel region (not individual voxels, as mk sometimes forgets)
#But we just print out the figs for regions responding to Jokes/Jokes custom, because that's the main result
rm(list = ls())
library(bootstrap)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
setwd("/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/analysis_pipeline")
meansig_outputs_folder = '/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/meansignal_outputs/'
########
#READ IN DATA
########
#New method: Read in the raw data from all_meansignal, that's much easier! Then condition on the
#column labeled fROIs to assign names appropriately. NOTE that this now takes care of reading
#in the localizer-to-localizer ones too, to facilitate making the supplemental materials.
allSigChange = read.csv(paste(meansig_outputs_folder, 'all_mean_signal_outputs.csv', sep=''))
#FOR NOW: Make a choice whether to do all analyses with top 50 voxels or top 10% voxels
allSigChange = filter(allSigChange, ind_selection_method == 'Top50Voxels')
# List contrast and ROI names so it's not just numbers!!!!! (This ordering comes from the
# standard ordering produced by the 2nd level analyses; we'll arrange differently in the plots)
RHLangROI.Names = c('RPost Temp', 'RAnt Temp', 'RAngG', 'RIFG',      'RMFG',     'RIFG orb');
LangROI.Names = c('LPost Temp', 'LAnt Temp', 'LAngG', 'LIFG',      'LMFG',     'LIFG orb');
MDROI.Names = c('LIFG op',  'RIFG op', 'LMFG',    'RMFG',    'LMFG orb',
'RMFG orb', 'LPrecG', 'RPrecG',  'LInsula', 'RInsula',
'LSMA',    'RSMA',   'LPar Inf', 'RPar Inf', 'LPar Sup',
'RPar Sup', 'LACC',   'RACC');
ToMROI.Names = c('DM PFC', 'LTPJ',  'MM PFC', 'PC',
'RTPJ',  'VM PFC', 'RSTS');
normal.contrasts = c('joke', 'lit', 'joke-lit')
custom.contrasts = c('low','med','high','other')
lang.contrasts = c('S','N','S-N')
MD.contrasts = c('H','E','H-E')
ToM.contrasts = c('bel','pho','bel-pho')
#Split the data into groups by fROIs, and rename them as appropriate
RHLang_sigs = data.frame(NULL)
LHLang_sigs = data.frame(NULL)
MD_sigs = data.frame(NULL)
ToM_sigs = data.frame(NULL)
RHLang_sigs = allSigChange %>%
filter(fROIs == 'RHLfROIs')%>%
mutate(ROIName = RHLangROI.Names[ROI]) %>%
group_by(task)%>%
mutate(contrastName = ifelse(task == 'Jokes', normal.contrasts[Contrast],
ifelse(task == 'JokesCustom', custom.contrasts[Contrast],
lang.contrasts[Contrast]))) %>%
mutate(Group = 'RHLang') %>%
ungroup()
LHLang_sigs = allSigChange %>%
filter(fROIs == 'LangfROIs')%>%
mutate(ROIName = LangROI.Names[ROI]) %>%
group_by(task)%>%
mutate(contrastName = ifelse(task == 'Jokes', normal.contrasts[Contrast],
ifelse(task == 'JokesCustom', custom.contrasts[Contrast],
lang.contrasts[Contrast]))) %>%
mutate(Group = 'LHLang') %>%
ungroup()
MD_sigs = allSigChange %>%
filter(fROIs == 'MDfROIs')%>%
mutate(ROIName = MDROI.Names[ROI]) %>%
group_by(task)%>%
mutate(contrastName = ifelse(task == 'Jokes', normal.contrasts[Contrast],
ifelse(task == 'JokesCustom', custom.contrasts[Contrast],
MD.contrasts[Contrast]))) %>%
mutate(Group = ifelse(ROI %%2 == 1, 'MDLeft','MDRight')) %>%
ungroup()
ToM_sigs = allSigChange %>%
filter(fROIs == 'ToMfROIs')%>%
mutate(ROIName = ToMROI.Names[ROI]) %>%
group_by(task)%>%
mutate(contrastName = ifelse(task == 'Jokes', normal.contrasts[Contrast],
ifelse(task == 'JokesCustom', custom.contrasts[Contrast],
ToM.contrasts[Contrast]))) %>%
mutate(Group = 'ToM') %>%
ungroup()
#And stick it all back together!!
allSigChange = rbind(RHLang_sigs, LHLang_sigs, MD_sigs, ToM_sigs)
#In addition to the by-region signal changes, we are going to give each person an average signal change value for each localizer
avgSigChange = aggregate(allSigChange$sigChange, by=list(allSigChange$Group,allSigChange$task, allSigChange$SubjectNumber,allSigChange$contrastName), mean)
names(avgSigChange) = c('Group', 'task', 'SubjectNumber', 'contrastName','sigChange')
avgSigChange$ROIName = 'LocalizerAverage'
avgSigChange$ROI = 0
allSigChange <- allSigChange %>%
dplyr::select(one_of(c('Group', 'task', 'ROIName', 'ROI','SubjectNumber', 'contrastName','sigChange')))
allSigChange <- rbind(allSigChange, avgSigChange)
#This rebuilds the t tests that spmss spits out from the individual signal change values (reproduced here from ind.
#signal change values so mk can track how those are done/feed into other analyses)
library(tidyr)
library(dplyr)
library(pwr)
#Set wd!
setwd("/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/analysis_pipeline")
#Make sure allSigChange is loaded. If it's not, run 2figs_resp_jokes.R to at least line 108
View(allSigChange)
#For the replication, commenting this out, we'll find out in a minute if any localizer-to-localizer
#measurements are not robust enough
#New 10/12: Localizer analysis shows that VMPFC localizer doesn't come out in this dataset, so remove it from
#the joke-lit tests for ToM and ToM custom (but leave it for the localizer itself)
#Replication: Nothing looks like it should be left out yet!
#allSigChange = allSigChange %>%
#  filter(!(Group == 'ToM' & ROIName =='VMPFC')) %>%
#  filter(!(Group == 'ToMCustom' & ROIName =='VMPFC'))
#######
# Calculate T Tests
#######
allTests <- allSigChange %>%
group_by(Group, task)%>%
summarize(familySize = length(unique(ROI))) %>%
merge(allSigChange) %>%
group_by(Group, task, ROI, ROIName, contrastName, familySize) %>%
summarise(t = t.test(sigChange, mu=0,alt='greater')$statistic,
p = t.test(sigChange, mu=0,alt='greater')$p.value) %>%
ungroup()%>%
group_by(Group, contrastName)%>%
mutate(p.adj = p.adjust(p, method="fdr", n=familySize[1]))%>%
ungroup()
View(allTests)
zz = file('localizer_t_tests_all.csv', 'w')
write.csv(allTests, zz, row.names=FALSE)
close(zz)
#Do corrections ever matter?
allTests <- allTests %>%
mutate(sig = p < 0.05) %>%
mutate(sigCor = p.adj < 0.05) %>%
mutate(mismatch = sig != sigCor)
View(filter(allTests,mismatch))
#Convention: when all tests go one way, report them together as follows:
reportTests <- function(ts, ps){
if (all(ps > 0.05)){
paste('all insig, ts <', max(ts), 'ps>', min(ps))
} else if (all(ps < 0.05)){
paste('all sig, ts >', min(ts), 'ps<', max(ps))
} else {
'explore...'
}
}
allTests %>%
filter(Group == 'RHLang', task == 'Jokes', contrastName == 'joke') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'RHLang', task == 'Jokes', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'LHLang', task == 'Jokes', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'MDRight', task == 'Jokes', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
