#Add distance-from-mean, and do a summary table!
oddballSubj <- behavdata %>%
mutate(distanceFromMean = response - meanResponse) %>%
group_by(ID, category) %>%
summarize(myMeanDistance = mean(distanceFromMean, na.rm=TRUE))
#Visualize that....
ggplot(data=oddballSubj, aes(y=myMeanDistance, x=category)) +
geom_point(stat = "identity")
#Is there anyone who is an outlier? Do a boxplot to see
# (Details: ) The upper whisker extends from the hinge to the largest value no further than 1.5 * IQR from the hinge (where IQR is the inter-quartile range, or distance between the first and third quartiles). The lower whisker extends from the hinge to the smallest value at most 1.5 * IQR of the hinge. Data beyond the end of the whiskers are called "outlying" points and are plotted individually.
ggplot(data=oddballSubj, aes(y=myMeanDistance, x=category)) +
geom_boxplot(stat = "boxplot") +
xlab('') +
ylab('Average distance from other subjects\' ratings')
#Interpretation: there are two people who found the NONjokes a bit funnier than we might expect, e.g. ~0.5 points funnier than the average person, that's it.
#(This is about half the observed effect size, jokes are about 1 point funnier than nonjokes over the whole dataset)
#########
# (((EXPLORATORY C - Appears in Supplemental section 6)))
#########
#FROM EV:
#get the average joke>non-joke effect size from Study 1 vs. Study 2,
#and correlate these. I'd be curious to see correlations
#* within each of the 5 sets of fROIs,
#* across all fROIs in the first three sets
#* across all fROIs
#This would give us a sense of how consistent the relative sizes of the
#effects across systems and fROIs are across studies.
#Load big matrix of stats from E1 and E2 used to make the main graphs
setwd(analysisfolder)
load('figs/mystats.RData')
jokelits <- mystats %>%
ungroup() %>%
filter(contrastName == 'joke-lit') %>%
select(c(ROIMask, localizer, ROIName, Experiment, themean)) %>%
filter(ROIName != "average\nacross\nfROIs") %>%
filter(localizer != 'Cloudy')%>%
mutate(Experiment = ifelse(Experiment == "Experiment 1", 'Experiment1', 'Experiment2')) %>%
spread(Experiment, themean) %>%
filter(ROIName != "VMPFC") %>% #VMPFC was dropped from E1 therefore from these comparisons
mutate(ROIName_noN = gsub("\n","", ROIName))
cor_labels <- jokelits %>%
group_by(ROIMask) %>%
summarize(group_cor = cor(Experiment1, Experiment2, method="spearman")) %>%
mutate(my_cor_label = paste("\u03C1=", round(group_cor, 3)))
#A Graph
library(ggrepel)
ggplot(data=jokelits, aes(y=Experiment2, x=Experiment1, color = ROIMask)) +
facet_wrap(~ ROIMask, ncol=3, scales = "free") +
geom_smooth(method="lm", se=FALSE) +
geom_point() +
expand_limits(x = 0, y = 0) +
xlab('Joke>Non-Joke signal change, \nExperiment 1') +
ylab('Joke>Non-Joke signal change, \nExperiment 2') +
geom_text_repel(aes(label = ROIName_noN), box.padding = unit(0.4, "lines"),
size = 3, color="black") +
geom_text(data=cor_labels, aes(label=my_cor_label),
x=Inf, y=-Inf, hjust=1, vjust=-0.6,
colour="black", inherit.aes=FALSE, parse=FALSE) +
theme(legend.position="none") +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black")) +
ggsave(filename="figs/exploratory_compare_activation_E1_E2.jpg", width=9, height=6)
cor(jokelits$Experiment1, jokelits$Experiment2, method="spearman")
#Takehome: activations within each system are relatively well correlated with 1 another.
#Accompanying statistical analysis! Experiment 1 finds NO CHANGE in RHLang and MDRight, while Experiment 2 finds a change.
#But, can we actually measure that difference, or are we underpowered? Compare values to each other....
View(all_allSignalChange) #Comes from #5, run that file to line 120)
#Wait! Make double sure we don't accidentally treat E2 subjects as re-measurements of E1 ones.
allSignalChange_Exploratory <- all_allSigChange %>%
mutate(realSubjN = paste(Experiment, participantID)) %>%
select(-participantID)
#Model comparison time!
RHLang <- filter(allSignalChange_Exploratory, ROIMask == "RHLang", localizer == "Lang", task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName*Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = RHLang)
m0 <- lmer(sigChange ~ contrastName+Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = RHLang)
anova(m1,m0)
MDRight <- filter(allSignalChange_Exploratory,  ROIMask == "MDRight", localizer == "MD", task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName*Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = MDRight)
m0 <- lmer(sigChange ~ contrastName+Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = MDRight)
anova(m1,m0)
ToM <- filter(allSignalChange_Exploratory,  ROIMask == "ToM", localizer == 'ToM', task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName*Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = ToM)
m0 <- lmer(sigChange ~ contrastName+Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = ToM)
anova(m1,m0)
LHLang <- filter(allSignalChange_Exploratory, ROIMask == "LHLang", localizer =='Lang', task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName*Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = LHLang)
m0 <- lmer(sigChange ~ contrastName+Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = LHLang)
anova(m1,m0)
MDLeft <- filter(allSignalChange_Exploratory,  ROIMask == "MDLeft", localizer == 'MD', task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName*Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = MDLeft)
m0 <- lmer(sigChange ~ contrastName+Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = MDLeft)
anova(m1,m0)
#########
#EXPLORATORY E - reported in Supplemental 6
#########
#Exploratory analysis: How do the signal changes for Joke > NonJoke compare to the localizer signal change in each
#ROI? Are these *proportions* different for the different signals?  (Looking at just E2)
localizer2task <- allSigChange %>%
filter(contrastName %in% c('joke-lit','H-E','S-N','bel-pho')) %>%
filter(task != 'JokesCustom') %>%
filter(localizer != 'Cloudy')%>%
filter(ROIName != 'LocalizerAverage') %>%
mutate(taskType = ifelse(task == 'Jokes', 'Critical', 'Localizer'))
#Composite graphs! Make sure necessary E2 data is loaded (lines 9-12)
library(dplyr)
library(stringr)
library(bootstrap)
library(ggplot2)
#(set your own wd first)
repodir = "/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis"
analysisfolder = paste(repodir, "/analysis_pipeline", sep="")
figfolder = paste(repodir, "/analysis_pipeline/figs", sep="")
E1folder = paste(repodir, "/E1_tabular_data", sep="")
setwd(analysisfolder)
load('avgRT.RData')
load('avgResponse.RData')
load('allSigChange.RData')
##############
#Now load up the data saved from experiment 1, and adjust column names to match
#Figure making starts around line 96
##############
#avg_RT dataframe
setwd(E1folder)
avgRT_E1 = read.csv('avgRT_Behavioral_Exp1.csv')
avgResponse_E1 = read.csv('avgResponse_Behavioral_Exp1.csv')
allSigChange_E1 = read.csv('allSigChange_Exp1.csv')
avgRT <- avgRT%>%
ungroup() %>%
mutate(Experiment = "Experiment 2", participantID = ID)%>%
select(-ID)%>%
mutate(meanRT = 1000 * meanRT)
avgRT_E1 <- avgRT_E1 %>%
mutate(participantID = newSubjectName, Experiment = "Experiment 1") %>%
select(-newSubjectName) %>%
mutate(meanRT = 1000 * meanRT)
all_avgRT <- bind_rows(avgRT, avgRT_E1)
all_avgRT <- all_avgRT %>%
mutate(Experiment = as.factor(Experiment),
category = as.factor(category))
#avgResponse dataframe
avgResponse <- avgResponse %>%
ungroup() %>%
mutate(Experiment = 'Experiment 2', participantID = ID)%>%
select(-ID)
avgResponse_E1 <- avgResponse_E1 %>%
mutate(participantID = newSubjectName, Experiment = "Experiment 1") %>%
select(-newSubjectName)
all_avgResponse <- bind_rows(avgResponse, avgResponse_E1)
all_avgResponse <- all_avgResponse %>%
mutate(Experiment = as.factor(Experiment),
category = as.factor(category))
#allSigChange dataframe
allSigChange_E1 = allSigChange_E1 %>%
#Column renaming-dropping
mutate(Experiment = 'Experiment 1', participantID = as.factor(SubjectNumber),
filename = "not given",
ind_selection_method = "Top10Percent",
pipeline = 'Old_evlab_pipeline') %>%
select(-one_of(c("ROI", "ROI.size",
"average.localizer.mask.size",
"inter.subject.overlap", "Contrast",
"SubjectNumber")))%>% #Drop subject number, misleading between experiments!
#Convert 'Group' to Mask-localizer-task format
mutate(ROIMask = ifelse(Group %in% c("RHLang", "RHLang-toLang"), "RHLang",
ifelse(Group %in% c("LHLang","LHLang-toLang"), "LHLang",
ifelse(Group %in% c("RevLangLeft-toMD", "MDLeft"), "MDLeft",
ifelse(Group %in% c("RevLangRight-toMD", "MDRight"), "MDRight", "ToM"))))) %>%
mutate(localizer = ifelse(Group %in% c("RHLang", "LHLang", "RHLang-toLang", "LHLang-toLang"), "Lang",
ifelse(Group %in% c("MDLeft", "MDRight"), "MD",
ifelse(Group %in% c("RevLangLeft-toMD","RevLangRight-toMD"), "RevLang", "ToM")))) %>%
mutate(task = ifelse(Group %in% c("RHLang-toLang", "LHLang-toLang"), "Lang",
ifelse(Group %in% c("RevLangLeft-toMD", "RevLangRight-toMD"), "MD",
ifelse(Group %in% c("ToM-to-ToM"), "ToM",
ifelse(Group %in% c("RHLang","LHLang","MDLeft","MDRight","ToM"), "Jokes", "JokesCustom")))))%>%
select(-Group) %>%
mutate(ROIName = str_replace(ROIName, " ",""))
allSigChange = allSigChange %>%
mutate(Experiment = 'Experiment 2') %>%
select(-one_of(c("SubjectNumber", "Evlab_SubNo")))%>% #Drop subject number, misleading between experiments!
mutate(ROIName = str_replace(ROIName, " ",""))
all_allSigChange = bind_rows(allSigChange, allSigChange_E1)
#Additional cleanups in factor levels
all_allSigChange = all_allSigChange %>%
mutate(contrastName = str_replace(contrastName, "H-E", "hard-easy"))%>%
mutate(contrastName = str_replace(contrastName, "S-N", "sent-non"))%>%
mutate(contrastName = str_replace(contrastName, "E", "easy"))%>%
mutate(contrastName = str_replace(contrastName, "H", "hard"))%>%
mutate(contrastName = str_replace(contrastName, "S", "sent"))%>%
mutate(contrastName = str_replace(contrastName, "N", "non"))%>%
mutate(contrastName = str_replace(contrastName, "paramfun", "linear"))
#Oh surprise, never calculated LocalizerAverage in E1
E1avgs <- all_allSigChange %>%
filter(Experiment == "Experiment 1")%>%
group_by(ROIMask, localizer, task, contrastName, participantID) %>%
summarize(ROIName = 'LocalizerAverage', sigChange = (mean(sigChange)))%>%
mutate(Experiment = 'Experiment 1', filename = "not given", pipeline = "Old_evlab_pipeline", ind_selection_method = "Top10Percent")
all_allSigChange = bind_rows(all_allSigChange, E1avgs)
#....and repair factor columns which are now in dissaray
tofactor <- c("task", "participantID", "ROIName", "contrastName",
"ROIMask", "localizer","Experiment")
all_allSigChange[tofactor] <- lapply(all_allSigChange[tofactor], factor)
#EXPLORATORY ANALYSES LIVE HERE.
#Load libraries
library(bootstrap)
library(dplyr)
library(lme4)
library(tidyr)
library(ggplot2)
library(stringr)
library(reshape2)
bootup <- function(mylist){
foo <- bootstrap(mylist, 1000, mean)
return(quantile(foo$thetastar, 0.975)[1])
}
bootdown <- function(mylist){
foo <- bootstrap(mylist, 1000, mean)
return(quantile(foo$thetastar, 0.025)[1])
}
repodir = "/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis"
analysisfolder = paste(repodir, "/analysis_pipeline", sep="")
figfolder = paste(repodir, "/analysis_pipeline/figs", sep="")
E1folder = paste(repodir, "/E1_tabular_data", sep="")
behavfolder = paste(repodir, "/E2_behavioral_data/Jokes", sep="")
setwd(analysisfolder)
#(set your own wd first)
###########
#(((EXPLORATORY A - Extend the high-med-low individual joke rating tests to the other systems. Appears in Supplemental 2)))
##########
#after powering the study up for the replication, we now detect (probably smaller) significant effects
#in all systems for jokes > nonjokes. The ToM ones are > RHLang and RMD (good!) but not significantly different in magnitude to
#Lang or MDL.  One way to show that those MD and RHL activations are tapping something other than humor in the task would be if
#funniness ratings didn't correlate with activation strength.  Let's see! (Oh wait, pause, this requires running more first level
#analyses to get those contrasts.  Check with Ev first. )
#(In fact, funniness ratings do correlate with activations in these regions as well)
#Load all the t tests (from E2)
allTests <- read.csv('jokes_t_tests_all.csv')
allTests <- allTests %>%
mutate(sig = p < 0.05) %>%
mutate(sigCor = p.adj < 0.05) %>%
mutate(mismatch = sig != sigCor)
filter(allTests,mismatch)
#(Note this gives only differences from fixation, no critical condition-condition contrasts)
#STOP HAMMER TIME Load the full result set for all signal changes
load('allSigChange.RData')
View(allSigChange)
#Convention: when all tests go one way, report them together as follows:
reportTests <- function(ts, ps){
if (all(ps > 0.05)){
paste('all insig, ts <', max(ts), 'ps>', min(ps))
} else if (all(ps < 0.05)){
paste('all sig, ts >', min(ts), 'ps<', max(ps))
} else {
'explore...'
}
}
#Extend the paramfun contrasts of the critical task to measure them in lang and in MD!
allTests %>%
filter(ROIMask == 'RHLang', task == 'JokesCustom', contrastName == 'linear') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(ROIMask == 'LHLang', task == 'JokesCustom', contrastName == 'linear') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(ROIMask == 'MDRight', task == 'JokesCustom', contrastName == 'linear') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(ROIMask == 'MDLeft', task == 'JokesCustom', contrastName == 'linear') %>%
summarise(n(), sum(sig), reportTests(t,p))
#Now the same, with LME for all parcels in the localizers
RHLCustom <- filter(allSigChange, ROIMask == "RHLang", task == 'JokesCustom', contrastName == 'low' | contrastName == 'med' | contrastName == 'high')
#Make sure those factors are ordered....
RHLCustom$contrastName <- as.factor(RHLCustom$contrastName)
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = RHLCustom)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = RHLCustom)
anova(m1,m0)
LHLCustom <- filter(allSigChange, ROIMask == "LHLang", task == 'JokesCustom', contrastName == 'low' | contrastName == 'med' | contrastName == 'high')
#Make sure those factors are ordered....
LHLCustom$contrastName <- as.factor(LHLCustom$contrastName)
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = LHLCustom)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = LHLCustom)
anova(m1,m0)
MDRCustom <- filter(allSigChange, ROIMask == "MDRight", task == 'JokesCustom', contrastName == 'low' | contrastName == 'med' | contrastName == 'high')
#Make sure those factors are ordered....
MDRCustom$contrastName <- as.factor(MDRCustom$contrastName)
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = MDRCustom)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = MDRCustom)
anova(m1,m0)
MDLCustom <- filter(allSigChange, ROIMask == "MDLeft", task == 'JokesCustom', contrastName == 'low' | contrastName == 'med' | contrastName == 'high')
#Make sure those factors are ordered....
MDLCustom$contrastName <- as.factor(MDLCustom$contrastName)
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = MDLCustom)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = MDLCustom)
anova(m1,m0)
###########
#(((EXPLORATORY B - Checking for behaviorally 'oddball' subjects. Supplemental 6)))
##########
# There are some differences between studies 1 and 2! In particular, we see overall
# bumps in activation (J > NJ) for the other 2 systems, Lang and MD.
# One thing Ev wondered was whether there were any 'oddball' responders in our
# task who were evaluating the jokes very differently.  To determine this, we're going
# to try and calculate a value for each person, which is: "how far away from the mean
# response is this person's average answer"
#New  - read in the nicely formatted behavioral data we made!
behavdata = read.csv(paste(behavfolder, '/all_behavioral_output.csv', sep=''))
# Make a table that aggregates responses by *item* (not person)
avgItemResponse <- behavdata %>%
group_by(item, category) %>%
summarise(meanResponse = mean(response, na.rm=TRUE))
#Merge it back to the main table
behavdata <- merge(behavdata, avgItemResponse, by=c("item","category"))
#Add distance-from-mean, and do a summary table!
oddballSubj <- behavdata %>%
mutate(distanceFromMean = response - meanResponse) %>%
group_by(ID, category) %>%
summarize(myMeanDistance = mean(distanceFromMean, na.rm=TRUE))
#Visualize that....
ggplot(data=oddballSubj, aes(y=myMeanDistance, x=category)) +
geom_point(stat = "identity")
#Is there anyone who is an outlier? Do a boxplot to see
# (Details: ) The upper whisker extends from the hinge to the largest value no further than 1.5 * IQR from the hinge (where IQR is the inter-quartile range, or distance between the first and third quartiles). The lower whisker extends from the hinge to the smallest value at most 1.5 * IQR of the hinge. Data beyond the end of the whiskers are called "outlying" points and are plotted individually.
ggplot(data=oddballSubj, aes(y=myMeanDistance, x=category)) +
geom_boxplot(stat = "boxplot") +
xlab('') +
ylab('Average distance from other subjects\' ratings')
#Interpretation: there are two people who found the NONjokes a bit funnier than we might expect, e.g. ~0.5 points funnier than the average person, that's it.
#(This is about half the observed effect size, jokes are about 1 point funnier than nonjokes over the whole dataset)
#########
# (((EXPLORATORY C - Appears in Supplemental section 6)))
#########
#FROM EV:
#get the average joke>non-joke effect size from Study 1 vs. Study 2,
#and correlate these. I'd be curious to see correlations
#* within each of the 5 sets of fROIs,
#* across all fROIs in the first three sets
#* across all fROIs
#This would give us a sense of how consistent the relative sizes of the
#effects across systems and fROIs are across studies.
#Load big matrix of stats from E1 and E2 used to make the main graphs
setwd(analysisfolder)
load('figs/mystats.RData')
jokelits <- mystats %>%
ungroup() %>%
filter(contrastName == 'joke-lit') %>%
select(c(ROIMask, localizer, ROIName, Experiment, themean)) %>%
filter(ROIName != "average\nacross\nfROIs") %>%
filter(localizer != 'Cloudy')%>%
mutate(Experiment = ifelse(Experiment == "Experiment 1", 'Experiment1', 'Experiment2')) %>%
spread(Experiment, themean) %>%
filter(ROIName != "VMPFC") %>% #VMPFC was dropped from E1 therefore from these comparisons
mutate(ROIName_noN = gsub("\n","", ROIName))
cor_labels <- jokelits %>%
group_by(ROIMask) %>%
summarize(group_cor = cor(Experiment1, Experiment2, method="spearman")) %>%
mutate(my_cor_label = paste("\u03C1=", round(group_cor, 3)))
#A Graph
library(ggrepel)
ggplot(data=jokelits, aes(y=Experiment2, x=Experiment1, color = ROIMask)) +
facet_wrap(~ ROIMask, ncol=3, scales = "free") +
geom_smooth(method="lm", se=FALSE) +
geom_point() +
expand_limits(x = 0, y = 0) +
xlab('Joke>Non-Joke signal change, \nExperiment 1') +
ylab('Joke>Non-Joke signal change, \nExperiment 2') +
geom_text_repel(aes(label = ROIName_noN), box.padding = unit(0.4, "lines"),
size = 3, color="black") +
geom_text(data=cor_labels, aes(label=my_cor_label),
x=Inf, y=-Inf, hjust=1, vjust=-0.6,
colour="black", inherit.aes=FALSE, parse=FALSE) +
theme(legend.position="none") +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black")) +
ggsave(filename="figs/exploratory_compare_activation_E1_E2.jpg", width=9, height=6)
cor(jokelits$Experiment1, jokelits$Experiment2, method="spearman")
#Takehome: activations within each system are relatively well correlated with 1 another.
#Accompanying statistical analysis! Experiment 1 finds NO CHANGE in RHLang and MDRight, while Experiment 2 finds a change.
#But, can we actually measure that difference, or are we underpowered? Compare values to each other....
View(all_allSignalChange) #Comes from #5, run that file to line 120)
#Wait! Make double sure we don't accidentally treat E2 subjects as re-measurements of E1 ones.
allSignalChange_Exploratory <- all_allSigChange %>%
mutate(realSubjN = paste(Experiment, participantID)) %>%
select(-participantID)
#Model comparison time!
RHLang <- filter(allSignalChange_Exploratory, ROIMask == "RHLang", localizer == "Lang", task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName*Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = RHLang)
m0 <- lmer(sigChange ~ contrastName+Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = RHLang)
anova(m1,m0)
MDRight <- filter(allSignalChange_Exploratory,  ROIMask == "MDRight", localizer == "MD", task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName*Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = MDRight)
m0 <- lmer(sigChange ~ contrastName+Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = MDRight)
anova(m1,m0)
ToM <- filter(allSignalChange_Exploratory,  ROIMask == "ToM", localizer == 'ToM', task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName*Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = ToM)
m0 <- lmer(sigChange ~ contrastName+Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = ToM)
anova(m1,m0)
LHLang <- filter(allSignalChange_Exploratory, ROIMask == "LHLang", localizer =='Lang', task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName*Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = LHLang)
m0 <- lmer(sigChange ~ contrastName+Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = LHLang)
anova(m1,m0)
MDLeft <- filter(allSignalChange_Exploratory,  ROIMask == "MDLeft", localizer == 'MD', task == 'Jokes', contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName*Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = MDLeft)
m0 <- lmer(sigChange ~ contrastName+Experiment + (contrastName|ROIName) + (contrastName|realSubjN), data = MDLeft)
anova(m1,m0)
#########
#EXPLORATORY E - reported in Supplemental 6
#########
#Exploratory analysis: How do the signal changes for Joke > NonJoke compare to the localizer signal change in each
#ROI? Are these *proportions* different for the different signals?  (Looking at just E2)
localizer2task <- allSigChange %>%
filter(contrastName %in% c('joke-lit','H-E','S-N','bel-pho')) %>%
filter(task != 'JokesCustom') %>%
filter(localizer != 'Cloudy')%>%
filter(ROIName != 'LocalizerAverage') %>%
mutate(taskType = ifelse(task == 'Jokes', 'Critical', 'Localizer'))
m1 <- lmer(sigChange ~ taskType*ROIMask + (taskType|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','RHLang','MDRight')))
m0 <- lmer(sigChange ~ taskType+ROIMask + (taskType|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','RHLang','MDRight')))
anova(m1, m0)
m1 <- lmer(sigChange ~ taskType*ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','RHLang','MDRight')))
m0 <- lmer(sigChange ~ taskType+ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','RHLang','MDRight')))
anova(m1, m0)
#For each region, ask whether there's a difference. There is. This is not a very interesting analysis.
ToMmodel <- lmer(sigChange ~ taskType + (taskType|ROIName) + (taskType|participantID), data = filter(localizer2task, ROIMask == 'ToM'))
ToMmodel0 <- lmer(sigChange ~ 1 + (taskType|ROIName) + (taskType|participantID), data = filter(localizer2task, ROIMask == 'ToM'))
anova(ToMmodel, ToMmodel0)
#Ask whether there is a difference between ToM and the other right-hemisphere systems, using same randoms as above
m1 <- lmer(sigChange ~ taskType*ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','MDRight', 'RHLang')))
m0 <- lmer(sigChange ~ taskType+ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','MDRight', 'RHLang')))
anova(m1, m0)
m1 <- lmer(sigChange ~ taskType*ROIMask + (taskType|ROIName) + (taskType|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','MDRight', 'RHLang')))
m0 <- lmer(sigChange ~ taskType+ROIMask + (taskType|ROIName) + (taskType|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','MDRight', 'RHLang')))
anova(m1, m0)
#Ask whether there is a difference between ToM and the other right-hemisphere systems, using same randoms as above
m1 <- lmer(sigChange ~ taskType*ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','RHLang')))
m0 <- lmer(sigChange ~ taskType+ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','RHLang')))
anova(m1, m0)
#Ask whether there is a difference between ToM and the other right-hemisphere systems, using same randoms as above
m1 <- lmer(sigChange ~ taskType*ROIMask + (taskType|ROIName) + (taskType|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','RHLang')))
m0 <- lmer(sigChange ~ taskType+ROIMask + (taskType|ROIName) + (taskType|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','RHLang')))
anova(m1, m0)
#Followup with ToM over each of the others
m1 <- lmer(sigChange ~ taskType*ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','MDRight')))
m0 <- lmer(sigChange ~ taskType+ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','MDRight')))
anova(m1, m0)
m1 <- lmer(sigChange ~ taskType*ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','RHLang')))
m0 <- lmer(sigChange ~ taskType+ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','RHLang')))
anova(m1, m0)
#Followup with ToM over each of the others
m1 <- lmer(sigChange ~ taskType*ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','MDRight')))
m0 <- lmer(sigChange ~ taskType+ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','MDRight')))
anova(m1, m0)
#EXPLORATORY ANALYSES LIVE HERE.
#Load libraries
library(bootstrap)
library(dplyr)
library(lme4)
library(tidyr)
library(ggplot2)
library(stringr)
library(reshape2)
bootup <- function(mylist){
foo <- bootstrap(mylist, 1000, mean)
return(quantile(foo$thetastar, 0.975)[1])
}
bootdown <- function(mylist){
foo <- bootstrap(mylist, 1000, mean)
return(quantile(foo$thetastar, 0.025)[1])
}
repodir = "/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis"
analysisfolder = paste(repodir, "/analysis_pipeline", sep="")
figfolder = paste(repodir, "/analysis_pipeline/figs", sep="")
E1folder = paste(repodir, "/E1_tabular_data", sep="")
behavfolder = paste(repodir, "/E2_behavioral_data/Jokes", sep="")
setwd(analysisfolder)
#(set your own wd first)
###########
#(((EXPLORATORY A - Extend the high-med-low individual joke rating tests to the other systems. Appears in Supplemental 2)))
##########
#after powering the study up for the replication, we now detect (probably smaller) significant effects
#in all systems for jokes > nonjokes. The ToM ones are > RHLang and RMD (good!) but not significantly different in magnitude to
#Lang or MDL.  One way to show that those MD and RHL activations are tapping something other than humor in the task would be if
#funniness ratings didn't correlate with activation strength.  Let's see! (Oh wait, pause, this requires running more first level
#analyses to get those contrasts.  Check with Ev first. )
#(In fact, funniness ratings do correlate with activations in these regions as well)
#Load all the t tests (from E2)
allTests <- read.csv('jokes_t_tests_all.csv')
allTests <- allTests %>%
mutate(sig = p < 0.05) %>%
mutate(sigCor = p.adj < 0.05) %>%
mutate(mismatch = sig != sigCor)
filter(allTests,mismatch)
#(Note this gives only differences from fixation, no critical condition-condition contrasts)
#STOP HAMMER TIME Load the full result set for all signal changes
load('allSigChange.RData')
View(allSigChange)
localizer2task <- allSigChange %>%
filter(contrastName %in% c('joke-lit','H-E','S-N','bel-pho')) %>%
filter(task != 'JokesCustom') %>%
filter(localizer != 'Cloudy')%>%
filter(ROIName != 'LocalizerAverage') %>%
mutate(taskType = ifelse(task == 'Jokes', 'Critical', 'Localizer'))
m1 <- lmer(sigChange ~ taskType*ROIMask + (taskType|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','RHLang','MDRight')))
m0 <- lmer(sigChange ~ taskType+ROIMask + (taskType|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','RHLang','MDRight')))
anova(m1, m0)
m1 <- lmer(sigChange ~ taskType*ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','MDRight', 'RHLang')))
m0 <- lmer(sigChange ~ taskType+ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','MDRight', 'RHLang')))
anova(m1, m0)
#Followup with ToM over each of the others
m1 <- lmer(sigChange ~ taskType*ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','MDRight')))
m0 <- lmer(sigChange ~ taskType+ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','MDRight')))
anova(m1, m0)
m1 <- lmer(sigChange ~ taskType*ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','RHLang')))
m0 <- lmer(sigChange ~ taskType+ROIMask + (1|ROIName) + (1|participantID), data = filter(localizer2task, ROIMask %in% c('ToM','RHLang')))
anova(m1, m0)
