ungroup()
ToM_sigs = allSigChange %>%
filter(fROIs == 'ToMfROIS')%>% ##Typo in all the filenames!
mutate(ROIName = ToMROI.Names[ROI]) %>%
group_by(task)%>%
mutate(contrastName = ifelse(task == 'Jokes', normal.contrasts[Contrast],
ifelse(task == 'JokesCustom', custom.contrasts[Contrast],
ToM.contrasts[Contrast]))) %>%
mutate(Group = 'ToM') %>%
ungroup()
#And stick it all back together!!
allSigChange = rbind(RHLang_sigs, LHLang_sigs, MD_sigs, ToM_sigs)
#In addition to the by-region signal changes, we are going to give each person an average signal change value for each localizer, each task
avgSigChange = aggregate(allSigChange$sigChange, by=list(allSigChange$Group,allSigChange$task, allSigChange$SubjectNumber,allSigChange$contrastName), mean)
names(avgSigChange) = c('Group', 'task', 'SubjectNumber', 'contrastName','sigChange')
avgSigChange$ROIName = 'LocalizerAverage'
avgSigChange$ROI = 0
allSigChange <- allSigChange %>%
dplyr::select(one_of(c('Group', 'task', 'ROIName', 'ROI','SubjectNumber', 'contrastName','sigChange')))
allSigChange <- rbind(allSigChange, avgSigChange)
#NOTE: Later scripts require this allSigChange object to be loaded into memory, run this script to here if it's missing
#This rebuilds the t tests that spmss spits out from the individual signal change values (reproduced here from ind.
#signal change values so mk can track how those are done/feed into other analyses)
library(tidyr)
library(dplyr)
library(pwr)
#Set wd!
setwd("/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/analysis_pipeline")
#Make sure allSigChange is loaded. If it's not, run 2figs_resp_jokes.R to at least line 108
View(allSigChange)
#For the replication, commenting this out, we'll find out in a minute if any localizer-to-localizer
#measurements are not robust enough
#New 10/12: Localizer analysis shows that VMPFC localizer doesn't come out in this dataset (replication/study 2), so DONT remove it from
#the joke-lit tests for ToM and ToM custom
#Replication: Nothing looks like it should be left out yet!
#allSigChange = allSigChange %>%
#  filter(!(Group == 'ToM' & ROIName =='VMPFC')) %>%
#  filter(!(Group == 'ToMCustom' & ROIName =='VMPFC'))
#######
# Calculate T Tests
#######
allTests <- allSigChange %>%
group_by(Group, task)%>%
summarize(familySize = length(unique(ROI))) %>%
merge(allSigChange) %>%
group_by(Group, task, ROI, ROIName, contrastName, familySize) %>%
summarise(t = t.test(sigChange, mu=0,alt='greater')$statistic,
p = t.test(sigChange, mu=0,alt='greater')$p.value) %>%
ungroup()%>%
group_by(Group, contrastName)%>%
mutate(p.adj = p.adjust(p, method="fdr", n=familySize[1]))%>%
ungroup()
View(allTests)
zz = file('localizer_t_tests_all.csv', 'w')
write.csv(allTests, zz, row.names=FALSE)
close(zz)
########
# Report those T tests like we want for the paper
########
#Do corrections ever matter?
allTests <- allTests %>%
mutate(sig = p < 0.05) %>%
mutate(sigCor = p.adj < 0.05) %>%
mutate(mismatch = sig != sigCor)
View(filter(allTests,mismatch))
#In the replication set, one mismatch: Nonwords over fixation in the linguistic task, LIFG orb, is
#significant before but not after correction. We don't care about this bc the interesting thing from
#that task is Sentences - Nonwords.
#Convention: when all tests go one way, report them together as follows:
reportTests <- function(ts, ps){
if (all(ps > 0.05)){
paste('all insig, ts <', max(ts), 'ps>', min(ps))
} else if (all(ps < 0.05)){
paste('all sig, ts >', min(ts), 'ps<', max(ps))
} else {
'explore...'
}
}
###
#RESP LOCALIZER
allTests %>%
filter(Group == 'LHLang', task == 'Lang', contrastName == 'S-N') %>%
summarise(n(), sum(sig), reportTests(t,p)) #Convention: when all significant, report the largest p
allTests %>%
filter(Group == 'RHLang', task == 'Lang', contrastName == 'S-N') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'MDLeft', task == 'MD', contrastName == 'H-E') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'MDRight', task == 'MD', contrastName == 'H-E') %>%
summarise(n(), sum(sig), reportTests(t,p)) #Orig found a surprise nonsig, but not in the replication
#(Note, in the orig we evaluated MD localizer with non-sent, but now we have participants with 2 localizer sessions!)
allTests %>%
filter(Group == 'ToM', task == 'ToM', contrastName == 'bel-pho') %>%
summarise(n(), sum(sig), reportTests(t,p))
###
#RESP JOKES
### RHLang
#Jokes and Nonjokes both activate, and this time differences! RAngG is nonsignificant
allTests %>%
filter(Group == 'RHLang', task == 'Jokes', contrastName == 'joke') %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'RHLang', contrastName == 'joke', !sig)
filter(allTests, Group == 'RHLang', contrastName == 'joke', sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'RHLang', task == 'Jokes', contrastName == 'lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'RHLang', contrastName == 'lit', !sig)
filter(allTests, Group == 'RHLang', contrastName == 'lit', sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'RHLang', task == 'Jokes', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
### LHLang
#Jokes and Nonjokes both activate, and this time there's differences?!
allTests %>%
filter(Group == 'LHLang', task == 'Jokes', contrastName == 'joke') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'LHLang', task == 'Jokes', contrastName == 'lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'LHLang', task == 'Jokes', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
### RHMD
allTests %>%
filter(Group == 'MDRight', task == 'Jokes', contrastName == 'joke') %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'MDRight', contrastName == 'joke', !sig)
allTests %>%
filter(Group == 'MDRight', task == 'Jokes',  contrastName == 'lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'MDRight', contrastName == 'lit', !sig)
allTests %>%
filter(Group == 'MDRight', task == 'Jokes', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'MDRight', contrastName == 'joke-lit', !sig)
filter(allTests, Group == 'MDRight', contrastName == 'joke-lit', sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
###LHMD
allTests %>%
filter(Group == 'MDLeft', task == 'Jokes', contrastName == 'joke') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'MDLeft', task == 'Jokes', contrastName == 'lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'MDLeft', contrastName == 'lit', !sig)
allTests %>%
filter(Group == 'MDLeft', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
### ToM
# Interesting activations!
allTests %>%
filter(Group == 'ToM', task =='Jokes', contrastName == 'joke') %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'ToM', contrastName == 'joke', sig)
allTests %>%
filter(Group == 'ToM', task =='Jokes', contrastName == 'lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'ToM', contrastName == 'lit', sig)
allTests %>%
filter(Group == 'ToM', task =='Jokes', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
#07/10/17 Where DID the paramfun go?  7/27 I found it! Whoops, and it has a different name in Study 1 and 2, which could cause problems...
#10/14 Huh, where did the ToM paramfun test go? Here it is again...
allTests %>%
filter(Group == 'ToM', task == 'JokesCustom', contrastName == 'linear') %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'ToM', contrastName == 'joke-lit', sig)
###############Here be exploratory analyses######
###############Exploratory analysis on Study 2
#Extend the paramfun contrasts of the critical task to measure them in lang and in MD!
allTests %>%
filter(Group == 'RHLang', task == 'JokesCustom', contrastName == 'linear') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'LHLang', task == 'JokesCustom', contrastName == 'linear') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'MDRight', task == 'JokesCustom', contrastName == 'linear') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'MDLeft', task == 'JokesCustom', contrastName == 'linear') %>%
summarise(n(), sum(sig), reportTests(t,p))
#Relating behavioral and contrast data by subjects!
library(tidyr)
library(dplyr)
library(lme4)
library(ggplot2)
library(bootstrap)
#(set your own wd first)
setwd("/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/analysis_pipeline")
behavdir = "/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/behavioral_data/Jokes"
#New  - read in the nicely formatted behavioral data we made!
behavdata = read.csv(paste(behavdir, '/all_behavioral_output.csv', sep=''))
#Make sure you have AllSigChange!
View(allSigChange)
#We need to make sure to match up the right participants, so here we add the list order that participants
#were loaded into the ToM initial first-level analyses.
participants = c('168_FED_20161228b_3T2',
'290_FED_20170426a_3T2',
'301_FED_20161217b_3T2',
'366_FED_20161205a_3T2',
'426_FED_20161215c_3T2',
'430_FED_20170426d_3T2',
'498_FED_20170210c_3T2',
'555_FED_20170426c_3T2',
'576_FED_20170414b_3T2',
'577_FED_20170414c_3T2',
'578_FED_20170414d_3T2',
'288_FED_20170412b_3T2',
'334_FED_20161221a_3T2',
'343_FED_20161208a_3T2',
'521_FED_20161228a_3T2',
'551_FED_20170412a_3T2',
'571_FED_20170412c_3T2',
'473_FED_20170210b_3T2',
'520_FED_20161227a_3T2',
'596_FED_20170426b_3T2')
participants = as.data.frame(participants)
participants$SubjectNumber = 1:nrow(participants)
participants$ID = participants$participant
allSigChange <- merge(allSigChange, participants, by=c('SubjectNumber'), all_x=TRUE, all_y=TRUE)
#(This drops any subjects who didn't get included for the Jokes analyses!)
####
# Ratings
####
#Get average ratings per category per participant
behavdata$response <- as.numeric(as.character(behavdata$response))
jokeResponseChange <- behavdata %>%
filter(!is.na(response)) %>%
group_by(ID, category) %>%
summarise(meanResponse = mean(response)) %>%
spread(category, meanResponse) %>%
mutate(meanResponseChange = joke-nonjoke)
####
# Signal change
####
jokeSigChange <- allSigChange %>%
filter(contrastName == 'joke-lit', Group == 'ToM', task == 'Jokes', ROIName == 'LocalizerAverage')
#Merge the datasets!
bb <- merge(jokeResponseChange, jokeSigChange, by=c('ID'))
## REPORT STATS
cor(bb$meanResponseChange, bb$sigChange)
## Added an LM (no random slopes/intercepts! just 1 value/person)
m1 <- lm(sigChange ~ meanResponseChange, data = bb)
m0 <- lm(sigChange ~ 1, data = bb)
anova(m1,m0)
######################
#Make the behavioral graphs for basic response times and ratings, (FIG 2)
# Drop NA response
behavdata <- filter(behavdata, !is.na(RT)) %>%
filter(!is.na(response))
####
# RT
####
#Get average RTs per category per participant
avgRT <- behavdata %>%
group_by(ID, category) %>%
summarise(meanRT = mean(RT))
#T test
t.test(meanRT ~ category, data=avgRT)
####
# Ratings
####
#Get average ratings per category per participant
behavdata$response <- as.numeric(as.character(behavdata$response))
avgResponse <- behavdata %>%
group_by(ID, category) %>%
summarise(meanResponse = mean(response))
t.test(meanResponse ~ category, data=avgResponse)
#Responses are different by condition! The jokes are funny!
View(behavdata)
names(behavdata)
avgItemResponse <- behavdata %>%
group_by(item, category) %>%
summarise(meanResponse = mean(response))
View(avgItemResponse)
names(avgItemResponse)
behavdata <- merge(behavdata, by=c("item","category"))
behavdata <- merge(behavdata, avgItemResponse, by=c("item","category"))
names(behavdata)
oddballSubj <- behavdata %>%
mutate(distanceFromMean = response - meanResponse) %>%
group_by(ID, category) %>%
summarize(myMeanDistance = mean(distanceFromMean))
View(oddballSubj)
ggplot(data=oddballSubj, aes(y=myMeanDistance, x=category)) +
geom_point(stat = identity)
ggplot(data=oddballSubj, aes(y=myMeanDistance, x=category) +
geom_point(stat = identity))
ggplot(data=oddballSubj, aes(y=myMeanDistance, x=category)) +
geom_point(stat = "identity")
#Is there anyone who is an outlier? Do a boxplot to see
ggplot(data=oddballSubj, aes(y=myMeanDistance, x=category)) +
geom_boxplot(stat = "boxplot", notch = TRUE)
ggplot(data=oddballSubj, aes(y=myMeanDistance, x=category)) +
geom_boxplot(stat = "boxplot")
ggplot(data=bb, aes(y=sigChange, x=meanResponseChange)) +
geom_point() +
geom_smooth(method="lm", se=FALSE) +
scale_y_continuous(limits = c(-0.25, 0.50), breaks = seq(-0.25, 0.50, 0.25)) +
scale_x_continuous(limits = c(0, 1.75), breaks = seq(0, 2, 0.5)) +
xlab('average rating response \n(Jokes - Non-jokes)') +
ylab('avg. % signal change \n(Jokes - Non-jokes)') +
theme_bw()
ggplot(data=toPlotResp, aes(y=mean, x=categoryLabel)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=bootdown, ymax=bootup), colour="black", width=.1, position=position_dodge(.9)) +
coord_cartesian(ylim=c(1,4)) +
scale_y_continuous(breaks = seq(1, 4, 1))+
xlab('Stimulus type') +
ylab('Average funny-ness rating') +
scale_fill_manual(name="", values=c("gray35", "gray60")) +
theme_bw() +
theme(legend.key = element_blank()) +
theme(strip.background = element_blank()) +
# Optional, remove for RHLang and ToMCustom since we want the legend there...
theme(legend.position="none")
#Relating behavioral and contrast data by subjects!
library(tidyr)
library(dplyr)
library(lme4)
library(ggplot2)
library(bootstrap)
#(set your own wd first)
setwd("/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/analysis_pipeline")
behavdir = "/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/behavioral_data/Jokes"
#New  - read in the nicely formatted behavioral data we made!
behavdata = read.csv(paste(behavdir, '/all_behavioral_output.csv', sep=''))
#Make sure you have AllSigChange!
View(allSigChange)
#We need to make sure to match up the right participants, so here we add the list order that participants
#were loaded into the ToM initial first-level analyses.
participants = c('168_FED_20161228b_3T2',
'290_FED_20170426a_3T2',
'301_FED_20161217b_3T2',
'366_FED_20161205a_3T2',
'426_FED_20161215c_3T2',
'430_FED_20170426d_3T2',
'498_FED_20170210c_3T2',
'555_FED_20170426c_3T2',
'576_FED_20170414b_3T2',
'577_FED_20170414c_3T2',
'578_FED_20170414d_3T2',
'288_FED_20170412b_3T2',
'334_FED_20161221a_3T2',
'343_FED_20161208a_3T2',
'521_FED_20161228a_3T2',
'551_FED_20170412a_3T2',
'571_FED_20170412c_3T2',
'473_FED_20170210b_3T2',
'520_FED_20161227a_3T2',
'596_FED_20170426b_3T2')
participants = as.data.frame(participants)
participants$SubjectNumber = 1:nrow(participants)
participants$ID = participants$participant
allSigChange <- merge(allSigChange, participants, by=c('SubjectNumber'), all_x=TRUE, all_y=TRUE)
#(This drops any subjects who didn't get included for the Jokes analyses!)
####
# Ratings
####
#Get average ratings per category per participant
behavdata$response <- as.numeric(as.character(behavdata$response))
jokeResponseChange <- behavdata %>%
filter(!is.na(response)) %>%
group_by(ID, category) %>%
summarise(meanResponse = mean(response)) %>%
spread(category, meanResponse) %>%
mutate(meanResponseChange = joke-nonjoke)
####
# Signal change
####
jokeSigChange <- allSigChange %>%
filter(contrastName == 'joke-lit', Group == 'ToM', task == 'Jokes', ROIName == 'LocalizerAverage')
#Merge the datasets!
bb <- merge(jokeResponseChange, jokeSigChange, by=c('ID'))
## REPORT STATS
cor(bb$meanResponseChange, bb$sigChange)
## Added an LM (no random slopes/intercepts! just 1 value/person)
m1 <- lm(sigChange ~ meanResponseChange, data = bb)
m0 <- lm(sigChange ~ 1, data = bb)
anova(m1,m0)
## MAKE PRETTY GRAPH
setwd("./figs")
coef(lm(meanResponseChange ~ sigChange, data = bb))
ggplot(data=bb, aes(y=sigChange, x=meanResponseChange)) +
geom_point() +
geom_smooth(method="lm", se=FALSE) +
scale_y_continuous(limits = c(-0.25, 0.50), breaks = seq(-0.25, 0.50, 0.25)) +
scale_x_continuous(limits = c(0, 1.75), breaks = seq(0, 2, 0.5)) +
xlab('average rating response \n(Jokes - Non-jokes)') +
ylab('avg. % signal change \n(Jokes - Non-jokes)') +
theme_bw() +
ggsave(filename="behav_activation.jpg", width=3, height=3)
######################
#Make the behavioral graphs for basic response times and ratings, (FIG 2)
# Drop NA response
behavdata <- filter(behavdata, !is.na(RT)) %>%
filter(!is.na(response))
####
# RT
####
#Get average RTs per category per participant
avgRT <- behavdata %>%
group_by(ID, category) %>%
summarise(meanRT = mean(RT))
#T test
t.test(meanRT ~ category, data=avgRT)
#Response times are not different by condition
####
# Ratings
####
#Get average ratings per category per participant
behavdata$response <- as.numeric(as.character(behavdata$response))
avgResponse <- behavdata %>%
group_by(ID, category) %>%
summarise(meanResponse = mean(response))
t.test(meanResponse ~ category, data=avgResponse)
#Responses are different by condition! The jokes are funny!
#### See below graphs for exploratory analyses.
####
# Graphs!
####
#sterr <- function(mylist){
#  my_se = sd(mylist)/sqrt(length(mylist))
#
#  return(my_se)
#}
#Edit! We should be doing bootstrapped 95% confidence intervals instead! calculate them from allSigChange
#then merge into mystats
bootup <- function(mylist){
foo <- bootstrap(mylist, 1000, mean)
return(quantile(foo$thetastar, 0.975)[1])
}
bootdown <- function(mylist){
foo <- bootstrap(mylist, 1000, mean)
return(quantile(foo$thetastar, 0.025)[1])
}
#Make the organized data for ggplot
avgRT <- ungroup(avgRT)
avgResponse <- ungroup(avgResponse)
#plot millisecnds
avgRT$meanRT <- avgRT$meanRT * 1000
#rename categories
avgRT$categoryLabel <- ""
avgRT[avgRT$category == "joke",]$categoryLabel <- "Jokes"
avgRT[avgRT$category == "nonjoke",]$categoryLabel <- "Non-Jokes"
avgResponse$categoryLabel <- ""
avgResponse[avgResponse$category == "joke",]$categoryLabel <- "Jokes"
avgResponse[avgResponse$category == "nonjoke",]$categoryLabel <- "Non-Jokes"
toPlotRT = avgRT %>%
group_by(categoryLabel)%>%
summarise(mean = mean(meanRT))
tobootUp = avgRT %>%
group_by(categoryLabel)%>%
summarise(bootup = bootup(meanRT))
tobootDown = avgRT %>%
group_by(categoryLabel)%>%
summarise(bootdown = bootdown(meanRT))
#toPlotRT = merge(toPlotRT, toStr)
#toPlotRT$se_up <- toPlotRT$mean + toPlotRT$sterr
#toPlotRT$se_down <- toPlotRT$mean - toPlotRT$sterr
toPlotRT = merge(toPlotRT, tobootUp)
toPlotRT = merge(toPlotRT, tobootDown)
toPlotResp = avgResponse %>%
group_by(categoryLabel)%>%
summarise(mean = mean(meanResponse))
#toStr = avgResponse %>%
#  group_by(categoryLabel)%>%
#  summarise(sterrRes = sterr(meanResponse))
#toPlotResp = merge(toPlotResp, toStr)
#toPlotResp$se_up <- toPlotResp$mean + toPlotResp$sterr
#toPlotResp$se_down <- toPlotResp$mean - toPlotResp$sterr
tobootUp = avgResponse %>%
group_by(categoryLabel)%>%
summarise(bootup = bootup(meanResponse))
tobootDown = avgResponse %>%
group_by(categoryLabel)%>%
summarise(bootdown = bootdown(meanResponse))
toPlotResp = merge(toPlotResp, tobootUp)
toPlotResp = merge(toPlotResp, tobootDown)
setwd(mywd)
ggplot(data=toPlotRT, aes(y=mean, x=categoryLabel)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=bootdown, ymax=bootup), colour="black", width=.1, position=position_dodge(.9)) +
coord_cartesian(ylim=c(0,1200)) +
scale_y_continuous(breaks = seq(0, 2000, 200))+
xlab('Stimulus type') +
ylab('Response time (milliseconds)') +
scale_fill_manual(name="", values=c("gray35", "gray60")) +
theme_bw() +
theme(legend.key = element_blank()) +
theme(strip.background = element_blank()) +
# Optional, remove for RHLang and ToMCustom since we want the legend there...
theme(legend.position="none")
ggsave(filename="behavioralrt.jpg", width=3, height=3)
ggplot(data=toPlotResp, aes(y=mean, x=categoryLabel)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=bootdown, ymax=bootup), colour="black", width=.1, position=position_dodge(.9)) +
coord_cartesian(ylim=c(1,4)) +
scale_y_continuous(breaks = seq(1, 4, 1))+
xlab('Stimulus type') +
ylab('Average funny-ness rating') +
scale_fill_manual(name="", values=c("gray35", "gray60")) +
theme_bw() +
theme(legend.key = element_blank()) +
theme(strip.background = element_blank()) +
# Optional, remove for RHLang and ToMCustom since we want the legend there...
theme(legend.position="none")
