a = fromJSON(df.complete.experiment_1$datastring[i])
df.wide$experiment[i] = df.complete.experiment_1$codeversion[i]
df.wide$participant[i] = i
df.wide$id[i] = a$workerId
if (is.null(a$questiondata$gender)){df.wide$gender[i] = NA
}else{
df.wide$gender[i] = a$questiondata$gender
}
df.wide$age[i] = a$questiondata$age
df.wide$condition[i] = a$condition
df.wide$counterbalance[i] = a$counterbalance
#cycles through the trials
for (j in 1:8){
df.wide[[paste("question_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[1]]
df.wide[[paste("rating_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[2]]
df.wide[[paste("throw_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[4]]
df.wide[[paste("grass_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[6]]
df.wide[[paste("distance_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[8]]
df.wide[[paste("wall_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[10]]
}
df.wide$feedback[i] = a$questiondata$feedback
}
df.long = wideToLong(subset(df.wide,select=-feedback),within="trial")
#create factors
df.long = mutate(df.long, question = as.factor(question),
throw = factor(throw,levels=c("low","high")),
grass = factor(grass,levels=c("low","high")),
distance = factor(distance,levels=c("short","long")),
wall = factor(wall,levels=c("no","yes")),
gender = factor(gender,levels=c("female","male","NA")),
age = as.numeric(age))
df.long = df.long[order(df.long$participant,df.long$question),]
# Packages ----------------------------------------------------------------
rm(list=ls())
library(lsr)
library(dplyr)
library(rjson)
library(RSQLite)
# Read data ---------------------------------------------------------------
con = dbConnect(SQLite(),dbname = "participants.db");
df.complete = dbReadTable(con,"almost") #change the name of the database here (mine was called "almost")
dbDisconnect(con)
#filter out incompletes
df.complete = subset(df.complete,status %in% c(3,4))
#save data of different experiments in separate data frames
df.complete.experiment_1 = subset(df.complete,codeversion == "experiment_1")
df.complete.experiment_2 = subset(df.complete,codeversion == "experiment_2")
df.complete.experiment_3 = subset(df.complete,codeversion == "experiment_3")
# EXP1: Structure data ----------------------------------------------------------
df.wide = data.frame(matrix(nrow=nrow(df.complete.experiment_1),ncol=8))
colnames(df.wide) = c("experiment","participant","id","gender","age","condition","counterbalance","feedback")
for (i in 1:nrow(df.wide)){
a = fromJSON(df.complete.experiment_1$datastring[i])
df.wide$experiment[i] = df.complete.experiment_1$codeversion[i]
df.wide$participant[i] = i
df.wide$id[i] = a$workerId
if (is.null(a$questiondata$gender)){df.wide$gender[i] = NA
}else{
df.wide$gender[i] = a$questiondata$gender
}
df.wide$age[i] = a$questiondata$age
df.wide$condition[i] = a$condition
df.wide$counterbalance[i] = a$counterbalance
#cycles through the trials
for (j in 1:8){
df.wide[[paste("question_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[1]]
df.wide[[paste("rating_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[2]]
df.wide[[paste("throw_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[4]]
df.wide[[paste("grass_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[6]]
df.wide[[paste("distance_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[8]]
df.wide[[paste("wall_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[10]]
}
df.wide$feedback[i] = a$questiondata$feedback
}
df.long = wideToLong(subset(df.wide,select=-feedback),within="trial")
#create factors
df.long = mutate(df.long, question = as.factor(question),
throw = factor(throw,levels=c("low","high")),
grass = factor(grass,levels=c("low","high")),
distance = factor(distance,levels=c("short","long")),
wall = factor(wall,levels=c("no","yes")),
gender = factor(gender,levels=c("female","male","NA")),
age = as.numeric(age))
df.long = df.long[order(df.long$participant,df.long$question),]
library(dplyr)
install.packages("dplyr")
library(plyr)
# Packages ----------------------------------------------------------------
rm(list=ls())
library(lsr)
library(dplyr)
library(rjson)
library(RSQLite)
# Read data ---------------------------------------------------------------
con = dbConnect(SQLite(),dbname = "participants.db");
df.complete = dbReadTable(con,"almost") #change the name of the database here (mine was called "almost")
dbDisconnect(con)
#filter out incompletes
df.complete = subset(df.complete,status %in% c(3,4))
#save data of different experiments in separate data frames
df.complete.experiment_1 = subset(df.complete,codeversion == "experiment_1")
df.complete.experiment_2 = subset(df.complete,codeversion == "experiment_2")
df.complete.experiment_3 = subset(df.complete,codeversion == "experiment_3")
# EXP1: Structure data ----------------------------------------------------------
df.wide = data.frame(matrix(nrow=nrow(df.complete.experiment_1),ncol=8))
colnames(df.wide) = c("experiment","participant","id","gender","age","condition","counterbalance","feedback")
for (i in 1:nrow(df.wide)){
a = fromJSON(df.complete.experiment_1$datastring[i])
df.wide$experiment[i] = df.complete.experiment_1$codeversion[i]
df.wide$participant[i] = i
df.wide$id[i] = a$workerId
if (is.null(a$questiondata$gender)){df.wide$gender[i] = NA
}else{
df.wide$gender[i] = a$questiondata$gender
}
df.wide$age[i] = a$questiondata$age
df.wide$condition[i] = a$condition
df.wide$counterbalance[i] = a$counterbalance
#cycles through the trials
for (j in 1:8){
df.wide[[paste("question_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[1]]
df.wide[[paste("rating_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[2]]
df.wide[[paste("throw_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[4]]
df.wide[[paste("grass_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[6]]
df.wide[[paste("distance_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[8]]
df.wide[[paste("wall_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[10]]
}
df.wide$feedback[i] = a$questiondata$feedback
}
df.long = wideToLong(subset(df.wide,select=-feedback),within="trial")
#create factors
df.long = mutate(df.long, question = as.factor(question),
throw = factor(throw,levels=c("low","high")),
grass = factor(grass,levels=c("low","high")),
distance = factor(distance,levels=c("short","long")),
wall = factor(wall,levels=c("no","yes")),
gender = factor(gender,levels=c("female","male","NA")),
age = as.numeric(age))
df.long = df.long[order(df.long$participant,df.long$question),]
library(lsr)
foo <- c(3,12,10,5)
dim(foo) <-c(2,2)
foo
foo <- c(3,12,7,10,5,6)
dim(foo) <-c(3,2)
foo
fisher.test(foo)
foo <- c(10,20,1,20)
dim(foo) <- c(2,2)
foo
chisq.test(foo)
fisher.test(foo)
installed.packages()
binomial.test([1 1 0 0 0 ], 0.5)
binomial.test(c(1 1 0 0 0 ), 0.5)
foo = c(1,2,2,2)
foo = c(0,1,1,1,1)
binomial.test(foo, 0.5)
binom.test(foo, 0.5)
binom.test(1,20,0)
binom.test(1,2000,0)
binom.test(1,2000,0.1)
binom.test(1,2000,0.5)
binom.test(1000,2000,0.5)
binom.test(1,2000,0, alternative="greater")
p = 0.032
p.adjust(p, n=20, method="fdr")
install.packages("rmarkdown")
version()
rversion()
install.packages('installr')
install.packages("installr")
install.packages('updater')
install.package('installr')
install.packages("installr")
install.packages("installr")
libraries
library(ggplot2)
install.packages("ggplot2")
#load_spmss_results
#
#This file loads the output of one of the results.csv files produced by the (mean signal) toolbox scripts into R.
#If I knew more about the mat file produced you could probably get all of this stuff out of
#there too.  But anyway this gets the mROI_data.csv file, sorts out its structure
#and reorganizes the data into proper longform. Take your analysis from there or save the result in a csv.
#Here, the csvs get saved back to the mean_signal folder for tidyness
library(dplyr)
library(tidyr)
library(stringr)
requireNamespace(plyr)
####
#Stuff to change!
myResultsPath = '/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Analysis Repository/All_Toolbox_Outputs/'
myOutputPath = '/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/'
whichResults = c('SplitHalf_LangfROIsrespNonlitJokes_20170904',
'SplitHalf_RHLangfROIsrespNonlitJokes_20170904',
'SplitHalf_MDfROIsrespNonlitJokes_20170904',
'SplitHalf_ToMfROIsrespNonlitJokes_20170904');
toSave = 1
####
#Leave the rest alone unless you're feeling fancy
all_mean_signal = data.frame(NULL)
for (result in whichResults){
setwd(paste(myResultsPath,result, sep=""))
#Open the weirdly formatted files and get just the table we want.
myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1)
lastsub = ncol(myfile)
myfile= myfile[complete.cases(myfile[,lastsub]),]#drop things past the individual % changes....
#To add: Look at the # of ROI parcels and their sizes, declare this to be a particular
#localizer, provide names for parcels. Also could add all that as an optional function arg.
#(this happens in 2_figs etc. now, but we do read the filenames to make that easier...)
#Add details about what this analysis is by splitting up the filename (requires regular filenames!)
rundetails = str_split_fixed(result, '_', 4)
myfROIs = rundetails[[1]]
myTask = rundetails[[3]]
myMethod = 'Top10Percent'
if(str_detect(rundetails[[4]], 'Top50')){myMethod = 'Top50Voxels'}
extract_val <- function(mystring, mynum){# fn to extract subject & contrast numbers
foo = str_split(mystring, "\\.")
myval = unlist(foo[[1]][mynum])
return(myval)
}
#Make the data beautiful and longform.
myfile[] <- lapply(myfile, as.character) #(Everything's a string, no factors)
myfile <- myfile %>%
gather("Subject_and_Cont", "sigChange", Subject.1.1.:ncol(myfile)) %>%
rowwise() %>%
mutate(SubjectNumber = extract_val(Subject_and_Cont, 2)) %>%
mutate(Contrast = extract_val(Subject_and_Cont, 3)) %>%
select(-Subject_and_Cont) %>%
rename(ROI = ROI.) %>%
mutate(filename = result)%>%
mutate(fROIs = myfROIs)%>%
mutate(task = myTask)%>%
mutate(ind_selection_method = myMethod)%>%
plyr::rename(replace = c(average.ROI.size="ROI.size"), warn_missing = FALSE)
#if string contains 'Top50'
#'LangFrois' etc.
#(rename critical)
#'Jokes'
#'JokesCustom'
#Optional: print back out a nice file with a more informative name.
if(toSave){
setwd(myOutputPath)
myFileName = paste(result,'.csv', sep="")
zz <- file(myFileName, "w")
write.csv(myfile, zz, row.names=FALSE)
close(zz)
}
#And add it to the giant dataframe
if (nrow(all_mean_signal) == 0){
all_mean_signal = myfile
}else{
all_mean_signal = rbind(all_mean_signal, myfile)
}
}
write.csv(all_mean_signal, 'SigChange_SplitHalf_E1.csv', row.names = FALSE)
#load_spmss_results
#
#This file loads the output of one of the results.csv files produced by the (mean signal) toolbox scripts into R.
#If I knew more about the mat file produced you could probably get all of this stuff out of
#there too.  But anyway this gets the mROI_data.csv file, sorts out its structure
#and reorganizes the data into proper longform. Take your analysis from there or save the result in a csv.
#Here, the csvs get saved back to the mean_signal folder for tidyness
library(dplyr)
library(tidyr)
library(stringr)
requireNamespace(plyr)
####
#Stuff to change!
myResultsPath = '/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Analysis Repository/All_Toolbox_Outputs/'
myOutputPath = '/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/'
whichResults = c('SplitHalf_LangfROIsrespNonlitJokes_20170904',
'SplitHalf_RHLangfROIsrespNonlitJokes_20170904',
'SplitHalf_MDfROIsrespNonlitJokes_20170904',
'SplitHalf_ToMfROIsrespNonlitJokes_20170904');
toSave = 0
####
#Leave the rest alone unless you're feeling fancy
all_mean_signal = data.frame(NULL)
for (result in whichResults){
setwd(paste(myResultsPath,result, sep=""))
#Open the weirdly formatted files and get just the table we want.
myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1)
lastsub = ncol(myfile)
myfile= myfile[complete.cases(myfile[,lastsub]),]#drop things past the individual % changes....
#To add: Look at the # of ROI parcels and their sizes, declare this to be a particular
#localizer, provide names for parcels. Also could add all that as an optional function arg.
#(this happens in 2_figs etc. now, but we do read the filenames to make that easier...)
#Add details about what this analysis is by splitting up the filename (requires regular filenames!)
rundetails = str_split_fixed(result, '_', 4)
myfROIs = rundetails[[1]]
myTask = rundetails[[3]]
myMethod = 'Top10Percent'
if(str_detect(rundetails[[4]], 'Top50')){myMethod = 'Top50Voxels'}
extract_val <- function(mystring, mynum){# fn to extract subject & contrast numbers
foo = str_split(mystring, "\\.")
myval = unlist(foo[[1]][mynum])
return(myval)
}
#Make the data beautiful and longform.
myfile[] <- lapply(myfile, as.character) #(Everything's a string, no factors)
myfile <- myfile %>%
gather("Subject_and_Cont", "sigChange", Subject.1.1.:ncol(myfile)) %>%
rowwise() %>%
mutate(SubjectNumber = extract_val(Subject_and_Cont, 2)) %>%
mutate(Contrast = extract_val(Subject_and_Cont, 3)) %>%
select(-Subject_and_Cont) %>%
rename(ROI = ROI.) %>%
mutate(filename = result)%>%
mutate(fROIs = myfROIs)%>%
mutate(task = myTask)%>%
mutate(ind_selection_method = myMethod)%>%
plyr::rename(replace = c(average.ROI.size="ROI.size"), warn_missing = FALSE)
#if string contains 'Top50'
#'LangFrois' etc.
#(rename critical)
#'Jokes'
#'JokesCustom'
#Optional: print back out a nice file with a more informative name.
if(toSave){
setwd(myOutputPath)
myFileName = paste(result,'.csv', sep="")
zz <- file(myFileName, "w")
write.csv(myfile, zz, row.names=FALSE)
close(zz)
}
#And add it to the giant dataframe
if (nrow(all_mean_signal) == 0){
all_mean_signal = myfile
}else{
all_mean_signal = rbind(all_mean_signal, myfile)
}
}
write.csv(all_mean_signal, 'SigChange_SplitHalf_E1.csv', row.names = FALSE)
all_mean_signal
#load_spmss_results
#
#This file loads the output of one of the results.csv files produced by the (mean signal) toolbox scripts into R.
#If I knew more about the mat file produced you could probably get all of this stuff out of
#there too.  But anyway this gets the mROI_data.csv file, sorts out its structure
#and reorganizes the data into proper longform. Take your analysis from there or save the result in a csv.
#Here, the csvs get saved back to the mean_signal folder for tidyness
library(dplyr)
library(tidyr)
library(stringr)
requireNamespace(plyr)
####
#Stuff to change!
myResultsPath = '/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Analysis Repository/All_Toolbox_Outputs/'
myOutputPath = '/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/'
whichResults = c('SplitHalf_LangfROIsrespNonlitJokes_20170904_results',
'SplitHalf_RHLangfROIsrespNonlitJokes_20170904_results',
'SplitHalf_MDfROIsrespNonlitJokes_20170904_results',
'SplitHalf_ToMfROIsrespNonlitJokes_20170904_results');
toSave = 0
####
#Leave the rest alone unless you're feeling fancy
all_mean_signal = data.frame(NULL)
for (result in whichResults){
setwd(paste(myResultsPath,result, sep=""))
#Open the weirdly formatted files and get just the table we want.
myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1)
lastsub = ncol(myfile)
myfile= myfile[complete.cases(myfile[,lastsub]),]#drop things past the individual % changes....
#To add: Look at the # of ROI parcels and their sizes, declare this to be a particular
#localizer, provide names for parcels. Also could add all that as an optional function arg.
#(this happens in 2_figs etc. now, but we do read the filenames to make that easier...)
#Add details about what this analysis is by splitting up the filename (requires regular filenames!)
rundetails = str_split_fixed(result, '_', 4)
myfROIs = rundetails[[1]]
myTask = rundetails[[3]]
myMethod = 'Top10Percent'
if(str_detect(rundetails[[4]], 'Top50')){myMethod = 'Top50Voxels'}
extract_val <- function(mystring, mynum){# fn to extract subject & contrast numbers
foo = str_split(mystring, "\\.")
myval = unlist(foo[[1]][mynum])
return(myval)
}
#Make the data beautiful and longform.
myfile[] <- lapply(myfile, as.character) #(Everything's a string, no factors)
myfile <- myfile %>%
gather("Subject_and_Cont", "sigChange", Subject.1.1.:ncol(myfile)) %>%
rowwise() %>%
mutate(SubjectNumber = extract_val(Subject_and_Cont, 2)) %>%
mutate(Contrast = extract_val(Subject_and_Cont, 3)) %>%
select(-Subject_and_Cont) %>%
rename(ROI = ROI.) %>%
mutate(filename = result)%>%
mutate(fROIs = myfROIs)%>%
mutate(task = myTask)%>%
mutate(ind_selection_method = myMethod)%>%
plyr::rename(replace = c(average.ROI.size="ROI.size"), warn_missing = FALSE)
#if string contains 'Top50'
#'LangFrois' etc.
#(rename critical)
#'Jokes'
#'JokesCustom'
#Optional: print back out a nice file with a more informative name.
if(toSave){
setwd(myOutputPath)
myFileName = paste(result,'.csv', sep="")
zz <- file(myFileName, "w")
write.csv(myfile, zz, row.names=FALSE)
close(zz)
}
#And add it to the giant dataframe
if (nrow(all_mean_signal) == 0){
all_mean_signal = myfile
}else{
all_mean_signal = rbind(all_mean_signal, myfile)
}
}
write.csv(all_mean_signal, 'SigChange_SplitHalf_E1.csv', row.names = FALSE)
getwd()
#load_spmss_results
#
#This file loads the output of one of the results.csv files produced by the (mean signal) toolbox scripts into R.
#If I knew more about the mat file produced you could probably get all of this stuff out of
#there too.  But anyway this gets the mROI_data.csv file, sorts out its structure
#and reorganizes the data into proper longform. Take your analysis from there or save the result in a csv.
#Here, the csvs get saved back to the mean_signal folder for tidyness
library(dplyr)
library(tidyr)
library(stringr)
requireNamespace(plyr)
####
#Stuff to change!
myResultsPath = '/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Analysis Repository/All_Toolbox_Outputs/'
myOutputPath = '/Users/mekline/Dropbox/_Projects/Jokes - fMRI/Jokes-Replication-Analysis/'
whichResults = c('SplitHalf_LangfROIsrespNonlitJokes_20170904_results',
'SplitHalf_RHLangfROIsrespNonlitJokes_20170904_results',
'SplitHalf_MDfROIsrespNonlitJokes_20170904_results',
'SplitHalf_ToMfROIsrespNonlitJokes_20170904_results');
toSave = 0
####
#Leave the rest alone unless you're feeling fancy
all_mean_signal = data.frame(NULL)
for (result in whichResults){
setwd(paste(myResultsPath,result, sep=""))
#Open the weirdly formatted files and get just the table we want.
myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1)
lastsub = ncol(myfile)
myfile= myfile[complete.cases(myfile[,lastsub]),]#drop things past the individual % changes....
#To add: Look at the # of ROI parcels and their sizes, declare this to be a particular
#localizer, provide names for parcels. Also could add all that as an optional function arg.
#(this happens in 2_figs etc. now, but we do read the filenames to make that easier...)
#Add details about what this analysis is by splitting up the filename (requires regular filenames!)
rundetails = str_split_fixed(result, '_', 4)
myfROIs = rundetails[[1]]
myTask = rundetails[[3]]
myMethod = 'Top10Percent'
if(str_detect(rundetails[[4]], 'Top50')){myMethod = 'Top50Voxels'}
extract_val <- function(mystring, mynum){# fn to extract subject & contrast numbers
foo = str_split(mystring, "\\.")
myval = unlist(foo[[1]][mynum])
return(myval)
}
#Make the data beautiful and longform.
myfile[] <- lapply(myfile, as.character) #(Everything's a string, no factors)
myfile <- myfile %>%
gather("Subject_and_Cont", "sigChange", Subject.1.1.:ncol(myfile)) %>%
rowwise() %>%
mutate(SubjectNumber = extract_val(Subject_and_Cont, 2)) %>%
mutate(Contrast = extract_val(Subject_and_Cont, 3)) %>%
select(-Subject_and_Cont) %>%
rename(ROI = ROI.) %>%
mutate(filename = result)%>%
mutate(fROIs = myfROIs)%>%
mutate(task = myTask)%>%
mutate(ind_selection_method = myMethod)%>%
plyr::rename(replace = c(average.ROI.size="ROI.size"), warn_missing = FALSE)
#if string contains 'Top50'
#'LangFrois' etc.
#(rename critical)
#'Jokes'
#'JokesCustom'
#Optional: print back out a nice file with a more informative name.
if(toSave){
setwd(myOutputPath)
myFileName = paste(result,'.csv', sep="")
zz <- file(myFileName, "w")
write.csv(myfile, zz, row.names=FALSE)
close(zz)
}
#And add it to the giant dataframe
if (nrow(all_mean_signal) == 0){
all_mean_signal = myfile
}else{
all_mean_signal = rbind(all_mean_signal, myfile)
}
}
setwd(myOutputPath)
write.csv(all_mean_signal, 'SigChange_SplitHalf_E1.csv', row.names = FALSE)
